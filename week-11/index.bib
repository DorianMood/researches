 @article{Li_Zhang_Wan_He_2021,
  title        = {Bipartite Graph Network with Adaptive Message Passing for Unbiased Scene Graph Generation},
  url          = {http://arxiv.org/abs/2104.00308},
  abstractnote = {Scene graph generation is an important visual understanding task with a broad range of vision applications. Despite recent tremendous progress, it remains challenging due to the intrinsic long-tailed class distribution and large intra-class variation. To address these issues, we introduce a novel confidence-aware bipartite graph neural network with adaptive message propagation mechanism for unbiased scene graph generation. In addition, we propose an efficient bi-level data resampling strategy to alleviate the imbalanced data distribution problem in training our graph network. Our approach achieves superior or competitive performance over previous methods on several challenging datasets, including Visual Genome, Open Images V4/V6, demonstrating its effectiveness and generality.},
  note         = {arXiv: 2104.00308},
  journal      = {arXiv:2104.00308 [cs]},
  author       = {Li, Rongjie and Zhang, Songyang and Wan, Bo and He, Xuming},
  year         = {2021},
  month        = {Apr}
}
 @article{Yang_Zhang_Zhang_Wu_Yang_2021,
  title        = {Probabilistic Modeling of Semantic Ambiguity for Scene Graph Generation},
  url          = {http://arxiv.org/abs/2103.05271},
  abstractnote = {To generate “accurate” scene graphs, almost all existing methods predict pairwise relationships in a deterministic manner. However, we argue that visual relationships are often semantically ambiguous. Specifically, inspired by linguistic knowledge, we classify the ambiguity into three types: Synonymy Ambiguity, Hyponymy Ambiguity, and Multi-view Ambiguity. The ambiguity naturally leads to the issue of emph{implicit multi-label}, motivating the need for diverse predictions. In this work, we propose a novel plug-and-play Probabilistic Uncertainty Modeling (PUM) module. It models each union region as a Gaussian distribution, whose variance measures the uncertainty of the corresponding visual content. Compared to the conventional deterministic methods, such uncertainty modeling brings stochasticity of feature representation, which naturally enables diverse predictions. As a byproduct, PUM also manages to cover more fine-grained relationships and thus alleviates the issue of bias towards frequent relationships. Extensive experiments on the large-scale Visual Genome benchmark show that combining PUM with newly proposed ResCAGCN can achieve state-of-the-art performances, especially under the mean recall metric. Furthermore, we prove the universal effectiveness of PUM by plugging it into some existing models and provide insightful analysis of its ability to generate diverse yet plausible visual relationships.},
  note         = {arXiv: 2103.05271},
  journal      = {arXiv:2103.05271 [cs]},
  author       = {Yang, Gengcong and Zhang, Jingyi and Zhang, Yong and Wu, Baoyuan and Yang, Yujiu},
  year         = {2021},
  month        = {Mar}
}
