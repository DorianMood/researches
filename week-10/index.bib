 @article{Chang_Ren_Xu_Li_Chen_Hauptmann_2021,
  title        = {Scene Graphs: A Survey of Generations and Applications},
  url          = {http://arxiv.org/abs/2104.01111},
  abstractnote = {Scene graph is a structured representation of a scene that can clearly express the objects, attributes, and relationships between objects in the scene. As computer vision technology continues to develop, people are no longer satisﬁed with simply detecting and recognizing objects in images; instead, people look forward to a higher level of understanding and reasoning about visual scenes. For example, given an image, we want to not only detect and recognize objects in the image, but also know the relationship between objects (visual relationship detection), and generate a text description (image captioning) based on the image content. Alternatively, we might want the machine to tell us what the little girl in the image is doing (Visual Question Answering (VQA)), or even remove the dog from the image and ﬁnd similar images (image editing and retrieval), etc. These tasks require a higher level of understanding and reasoning for image vision tasks. The scene graph is just such a powerful tool for scene understanding. Therefore, scene graphs have attracted the attention of a large number of researchers, and related research is often cross-modal, complex, and rapidly developing. However, no relatively systematic survey of scene graphs exists at present. To this end, this survey conducts a comprehensive investigation of the current scene graph research. More speciﬁcally, we ﬁrst summarized the general deﬁnition of the scene graph, then conducted a comprehensive and systematic discussion on the generation method of the scene graph (SGG) and the SGG with the aid of prior knowledge. We then investigated the main applications of scene graphs and summarized the most commonly used datasets. Finally, we provide some insights into the future development of scene graphs. We believe this will be a very helpful foundation for future research on scene graphs.},
  note         = {arXiv: 2104.01111},
  journal      = {arXiv:2104.01111 [cs]},
  author       = {Chang, Xiaojun and Ren, Pengzhen and Xu, Pengfei and Li, Zhihui and Chen, Xiaojiang and Hauptmann, Alex},
  year         = {2021},
  month        = {Mar}
}
 @inbook{Zhang_Wang_Guo_2019,
  place        = {Cham},
  series       = {Lecture Notes in Computer Science},
  title        = {Scene Graph Generation via Convolutional Message Passing and Class-Aware Memory Embeddings},
  volume       = {11729},
  isbn         = {978-3-030-30507-9},
  url          = {http://link.springer.com/10.1007/978-3-030-30508-6_49},
  doi          = {10.1007/978-3-030-30508-6_49},
  abstractnote = {Detecting visual relationships between objects in an image still remains challenging, because the relationships are diﬃcult to be modeled and the class imbalance problem tends to jeopardize the predictions. To alleviate these problems, we propose an end-to-end approach for scene graph generations. The proposed method employs the ResNet as the backbone network to extract the appearance features of the objects and relationships. An attention based graph convolutional network is exploited and modiﬁed to extract the contextual information. Language and geometric priors are also utilized and fused with the visual features to better describe the relationships. At last, a novel memory module is designed to alleviate the class imbalance problem. Experimental results demonstrate the validity of our model and our superiority compared to our baseline technique.},
  booktitle    = {Artificial Neural Networks and Machine Learning – ICANN 2019: Image Processing},
  publisher    = {Springer International Publishing},
  author       = {Zhang, Yidong and Wang, Yunhong and Guo, Yuanfang},
  editor       = {Tetko, Igor V. and Kůrková, Věra and Karpov, Pavel and Theis, Fabian},
  year         = {2019},
  pages        = {620–633},
  collection   = {Lecture Notes in Computer Science}
}
